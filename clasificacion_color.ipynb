{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN_Clasificador_COLOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTAR LIBRERÍAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AutoEncoder v1\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "#print(tf.__version__)==> VERSION DE TENSORFLOW  1.10\n",
    "import matplotlib\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Reshape, Conv2DTranspose, Dropout\n",
    "from tensorflow.keras.layers import Activation, Lambda, LSTM\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.losses import mean_squared_error # MeanSquaredError\n",
    "from tensorflow.keras import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle   #Lo tuve que agregar nuevamente porque me decía que no estaba definido cuando guarda los datos\n",
    "import skimage   #la version que se instla en conda es la 0.14.0 ==> hay que ver nombre de la funcion para metricas\n",
    "from skimage import measure\n",
    "from skimage import data, io,color\n",
    "import pydot\n",
    "from skimage.io import imread\n",
    "from skimage.io import imread_collection\n",
    "import skimage.color\n",
    "from sklearn import utils\n",
    "from IPython.display import Image\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CARGA DE LOS DATOS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ DATOS 0 #######################################\n",
    "dirName = '/home/lucas/Escritorio/proyecto_imagenes_CNN/Sign_Language_Digits_Dataset/Dataset/0/*.JPG'\n",
    "collection = imread_collection(dirName)                     #Creo una colection con todas las imagenes que hay en la carpeta\n",
    "x = skimage.io.concatenate_images(collection)               #Convierte la coleccion en numpy array concatenado.\n",
    "X_0 = x\n",
    "Y_0 = np.ones(len(x[:,0,0,0]))*0\n",
    "Y_0 = Y_0[:,np.newaxis]\n",
    "\n",
    "############################### DATOS 1 ########################################\n",
    "dirName = '/home/lucas/Escritorio/proyecto_imagenes_CNN/Sign_Language_Digits_Dataset/Dataset/1/*.JPG'\n",
    "collection = imread_collection(dirName)                         #Creo una colection con todas las imagenes que hay en la carpeta\n",
    "x = skimage.io.concatenate_images(collection)                   #Convierte la coleccion en numpy array concatenado.\n",
    "X_1 = x\n",
    "Y_1 = np.ones(len(x[:,0,0,0]))*1\n",
    "Y_1 = Y_1[:,np.newaxis]\n",
    "\n",
    "############################### DATOS 2 ########################################\n",
    "dirName = '/home/lucas/Escritorio/proyecto_imagenes_CNN/Sign_Language_Digits_Dataset/Dataset/2/*.JPG'\n",
    "collection = imread_collection(dirName)                         #Creo una colection con todas las imagenes que hay en la carpeta\n",
    "x = skimage.io.concatenate_images(collection)                   #Convierte la coleccion en numpy array concatenado.\n",
    "X_2 = x\n",
    "Y_2 = np.ones(len(x[:,0,0,0]))*2\n",
    "Y_2 = Y_2[:,np.newaxis]\n",
    "\n",
    "############################### DATOS 3 ########################################\n",
    "dirName = '/home/lucas/Escritorio/proyecto_imagenes_CNN/Sign_Language_Digits_Dataset/Dataset/3/*.JPG'\n",
    "collection = imread_collection(dirName)                         #Creo una colection con todas las imagenes que hay en la carpeta\n",
    "x = skimage.io.concatenate_images(collection)                   #Convierte la coleccion en numpy array concatenado.\n",
    "X_3 = x\n",
    "Y_3 = np.ones(len(x[:,0,0,0]))*3\n",
    "Y_3 = Y_3[:,np.newaxis]\n",
    "\n",
    "############################### DATOS 4 ########################################\n",
    "dirName = '/home/lucas/Escritorio/proyecto_imagenes_CNN/Sign_Language_Digits_Dataset/Dataset/4/*.JPG'\n",
    "collection = imread_collection(dirName)                         #Creo una colection con todas las imagenes que hay en la carpeta\n",
    "x = skimage.io.concatenate_images(collection)                   #Convierte la coleccion en numpy array concatenado.\n",
    "X_4 = x\n",
    "Y_4 = np.ones(len(x[:,0,0,0]))*4\n",
    "Y_4 = Y_4[:,np.newaxis]\n",
    "\n",
    "############################### DATOS 5 ########################################\n",
    "dirName = '/home/lucas/Escritorio/proyecto_imagenes_CNN/Sign_Language_Digits_Dataset/Dataset/5/*.JPG'\n",
    "collection = imread_collection(dirName)                         #Creo una colection con todas las imagenes que hay en la carpeta\n",
    "x = skimage.io.concatenate_images(collection)                   #Convierte la coleccion en numpy array concatenado.\n",
    "X_5 = x\n",
    "Y_5 = np.ones(len(x[:,0,0,0]))*5\n",
    "Y_5 = Y_5[:,np.newaxis]\n",
    "\n",
    "############################### DATOS 6 ########################################\n",
    "dirName = '/home/lucas/Escritorio/proyecto_imagenes_CNN/Sign_Language_Digits_Dataset/Dataset/6/*.JPG'\n",
    "collection = imread_collection(dirName)                         #Creo una colection con todas las imagenes que hay en la carpeta\n",
    "x = skimage.io.concatenate_images(collection)                   #Convierte la coleccion en numpy array concatenado.\n",
    "X_6 = x\n",
    "Y_6 = np.ones(len(x[:,0,0,0]))*6\n",
    "Y_6 = Y_6[:,np.newaxis]\n",
    "\n",
    "############################### DATOS 7 ########################################\n",
    "dirName = '/home/lucas/Escritorio/proyecto_imagenes_CNN/Sign_Language_Digits_Dataset/Dataset/7/*.JPG'\n",
    "collection = imread_collection(dirName)                         #Creo una colection con todas las imagenes que hay en la carpeta\n",
    "x = skimage.io.concatenate_images(collection)                   #Convierte la coleccion en numpy array concatenado.\n",
    "X_7 = x\n",
    "Y_7 = np.ones(len(x[:,0,0,0]))*7\n",
    "Y_7 = Y_7[:,np.newaxis]\n",
    "\n",
    "############################### DATOS 8 ########################################\n",
    "dirName = '/home/lucas/Escritorio/proyecto_imagenes_CNN/Sign_Language_Digits_Dataset/Dataset/8/*.JPG'\n",
    "collection = imread_collection(dirName)                         #Creo una colection con todas las imagenes que hay en la carpeta\n",
    "x = skimage.io.concatenate_images(collection)                   #Convierte la coleccion en numpy array concatenado.\n",
    "X_8 = x\n",
    "Y_8 = np.ones(len(x[:,0,0,0]))*8\n",
    "Y_8 = Y_8[:,np.newaxis]\n",
    "\n",
    "############################### DATOS 9 ########################################\n",
    "dirName = '/home/lucas/Escritorio/proyecto_imagenes_CNN/Sign_Language_Digits_Dataset/Dataset/9/*.JPG'\n",
    "collection = imread_collection(dirName)                         #Creo una colection con todas las imagenes que hay en la carpeta\n",
    "x = skimage.io.concatenate_images(collection)                   #Convierte la coleccion en numpy array concatenado.\n",
    "X_9 = x\n",
    "Y_9 = np.ones(len(x[:,0,0,0]))*9\n",
    "Y_9 = Y_9[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenacion de las imagenes y etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datos = np.vstack([X_0,X_1,X_2,X_3,X_4,X_5,X_6,X_7,X_8,X_9])\n",
    "etiquetas = np.vstack([Y_0,Y_1,Y_2,Y_3,Y_4,Y_5,Y_6,Y_7,Y_8,Y_9])\n",
    "print (np.shape(Datos))\n",
    "print (np.shape(etiquetas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle de datos y etiquetas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datos,etiquetas = utils.shuffle(Datos,etiquetas)\n",
    "\n",
    "print (etiquetas[195])\n",
    "io.imshow(Datos[195,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DIVISIÓN DE LOS DATOS  en TRAIN y TEST. Normalizacion de los Datos entre 0 y 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamaño_test=0.1 #representa la proporción del conjunto de datos que se incluirá en la división de prueba.\n",
    "tamaño_train=0.9 #representa la proporción del conjunto de datos que se incluirá en la división de prueba.\n",
    "\n",
    "p_test=int(len(Datos[:,1,1])*tamaño_test)\n",
    "p_train=int(len(Datos[:,1,1])*tamaño_train)\n",
    "\n",
    "x_test=Datos[0:p_test-1,:,:]/255\n",
    "x_train=Datos[p_test:p_train+p_test,:,:]/255\n",
    "\n",
    "Y_test=etiquetas[0:p_test-1,:]\n",
    "Y_train=etiquetas[p_test:p_train+p_test,:]\n",
    "\n",
    "print(np.shape(x_test))\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(Y_test))\n",
    "print(np.shape(Y_train))\n",
    "\n",
    "io.imshow(x_train[42,:])\n",
    "plt.show()\n",
    "print (Y_train[42])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = tf.keras.utils.to_categorical(Y_train, 10)\n",
    "Y_test = tf.keras.utils.to_categorical(Y_test, 10)\n",
    "print(np.shape(Y_test))\n",
    "print(Y_test[4,:])\n",
    "io.imshow(x_test[4,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADECUACIÓN DE LOS DATOS PARA EL ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos_tensor=tf.expand_dims(x_test, axis=3) #Esta función me devuelve un tensor, asique se debe pasar a array.\n",
    "X_test = x_test\n",
    "\n",
    "#Datos_tensor2=tf.expand_dims(x_train, axis=3) #Esta función me devuelve un tensor, asique se debe pasar a array.\n",
    "X_train = x_train\n",
    "\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASIFICADOR_CNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARQUITECTURA DE LA CNN:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Primera y segunda capa convolucionales\n",
    "# input: imagenes de 100x100 de tres canales -> tensores de la forma (100, 100, 3).\n",
    "# Acá se aplican dos capas convolucionales, las cuales consiten en 32 filtros de 3x3. Luego se aplican una capa de MaxPooling y un DropOut\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Tercera y cuarta capa convolucionales\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Capa Fully connected\n",
    "model.add(Flatten())   #REAPILA LA IMAGEN EN UN VECTOR\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Capa de salida Softmax\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para mostrar la arquitectura de la RED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True, rankdir='TB')\n",
    "Image(retina=True, filename='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilacion del modelo: declaracion de optimizador y funcion de perdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de la RED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 50\n",
    "porc_datos_validacion = 0.2\n",
    "\n",
    "red_CNN = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split = porc_datos_validacion,\n",
    "                    callbacks=[early_stopping],\n",
    "                    shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUACIÓN DEL MODELO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de la figura de los errores de entrenamiento y de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.title('Errores de entrenamiento\\n y de validación', fontsize = 16)\n",
    "plt.ylabel('Error', fontsize = 14)\n",
    "plt.xlabel('Épocas', fontsize = 14)\n",
    "# Los datos de los errores de train y validacion se deben acomodar\n",
    "plt.plot(red_CNN.history[\"loss\"][1:np.size(red_CNN.history[\"loss\"])], label=\"Training Loss\")\n",
    "plt.plot(red_CNN.history[\"val_loss\"][0:np.size(red_CNN.history[\"val_loss\"])-1], label=\"Validation Loss\")\n",
    "plt.legend(fontsize = 12)\n",
    "plt.grid(True)\n",
    "plt.savefig('/home/lucas/Escritorio/proyecto_imagenes_CNN/errores_entrenamiento_escala_RGB.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos para poder obtener la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = model.predict(X_test)\n",
    "pre = []\n",
    "tru = []\n",
    "for i,j in zip(predicciones, Y_test):\n",
    "    pre.append(np.argmax(i))\n",
    "    tru.append(np.argmax(j))\n",
    "\n",
    "print(np.array(pre))\n",
    "print(np.array(tru))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de la matriz de confusión y de las métricas Precisión y Exhaustividad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "cf_mt = confusion_matrix(tru, pre,normalize='true')\n",
    "print ('Matriz de confusión:\\n',cf_mt)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(tru,pre, average=None)\n",
    "print ('Precisión:\\n',precision)\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(tru, pre, average=None)\n",
    "print ('Recall:\\n', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "print (type(cf_mt))\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (9,7))\n",
    "ax = sns.heatmap(cf_mt, annot=True, cmap='Blues')\n",
    "\n",
    "ax.set_title('Matriz de Confusión\\n Imágenes en color RGB\\n', fontsize = 20);\n",
    "ax.set_xlabel('\\nPredicciones', fontsize = 17)\n",
    "ax.set_ylabel('Valores verdaderos', fontsize = 17);\n",
    "\n",
    "ax.xaxis.set_ticklabels(['0','1','2','3','4','5','6','7','8','9'])\n",
    "ax.yaxis.set_ticklabels(['0','1','2','3','4','5','6','7','8','9'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de la figura de la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('/home/lucas/Escritorio/proyecto_imagenes_CNN/matriz_de_confusion_RGB.pdf', bbox_inches = 'tight')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f37125ed7f73b9c3e7f69768a023a6c2f51bd8edf88b01931853c6f504e10049"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('env_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
